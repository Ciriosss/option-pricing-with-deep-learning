{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_9300\\2725669544.py:3: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Data/full_rnn_data_2.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastTradeDate</th>\n",
       "      <th>strike</th>\n",
       "      <th>price</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>change</th>\n",
       "      <th>percentChange</th>\n",
       "      <th>volume</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>sigma</th>\n",
       "      <th>...</th>\n",
       "      <th>ticker_ZS</th>\n",
       "      <th>ticker_ZTO</th>\n",
       "      <th>ticker_ZTS</th>\n",
       "      <th>ticker_ZUMZ</th>\n",
       "      <th>ticker_ZUO</th>\n",
       "      <th>ticker_ZVIA</th>\n",
       "      <th>ticker_ZVRA</th>\n",
       "      <th>ticker_ZWS</th>\n",
       "      <th>ticker_ZYME</th>\n",
       "      <th>ticker_ZYXI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>137.05</td>\n",
       "      <td>137.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717668.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.263417</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>137.05</td>\n",
       "      <td>137.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717668.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.263417</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>137.05</td>\n",
       "      <td>137.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717668.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.263417</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>137.05</td>\n",
       "      <td>137.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717668.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.263417</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>137.05</td>\n",
       "      <td>137.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717668.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.263417</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278709</th>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034596.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278710</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034596.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278711</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034596.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278712</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034596.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278713</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034596.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278714 rows × 4026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastTradeDate  strike  price     bid     ask  change  percentChange  \\\n",
       "0         2024-07-23    70.0   0.18  137.05  137.12     0.0            0.0   \n",
       "1         2024-07-23    70.0   0.18  137.05  137.12     0.0            0.0   \n",
       "2         2024-05-02    85.0   0.10  137.05  137.12     0.0            0.0   \n",
       "3         2024-05-02    85.0   0.10  137.05  137.12     0.0            0.0   \n",
       "4         2024-05-02    85.0   0.10  137.05  137.12     0.0            0.0   \n",
       "...              ...     ...    ...     ...     ...     ...            ...   \n",
       "278709    2024-05-15    17.5   0.35    8.90    8.96     0.0            0.0   \n",
       "278710    2024-03-06    20.0   0.50    8.90    8.96     0.0            0.0   \n",
       "278711    2024-03-06    20.0   0.50    8.90    8.96     0.0            0.0   \n",
       "278712    2024-03-06    20.0   0.50    8.90    8.96     0.0            0.0   \n",
       "278713    2024-03-06    20.0   0.50    8.90    8.96     0.0            0.0   \n",
       "\n",
       "           volume  openInterest     sigma  ... ticker_ZS  ticker_ZTO  \\\n",
       "0       1717668.0           2.0  0.263417  ...     False       False   \n",
       "1       1717668.0           2.0  0.263417  ...     False       False   \n",
       "2       1717668.0          16.0  0.263417  ...     False       False   \n",
       "3       1717668.0          16.0  0.263417  ...     False       False   \n",
       "4       1717668.0          16.0  0.263417  ...     False       False   \n",
       "...           ...           ...       ...  ...       ...         ...   \n",
       "278709  1034596.0         109.0  0.599988  ...     False       False   \n",
       "278710  1034596.0           2.0  0.599988  ...     False       False   \n",
       "278711  1034596.0           2.0  0.599988  ...     False       False   \n",
       "278712  1034596.0           2.0  0.599988  ...     False       False   \n",
       "278713  1034596.0           2.0  0.599988  ...     False       False   \n",
       "\n",
       "       ticker_ZTS  ticker_ZUMZ  ticker_ZUO  ticker_ZVIA  ticker_ZVRA  \\\n",
       "0           False        False       False        False        False   \n",
       "1           False        False       False        False        False   \n",
       "2           False        False       False        False        False   \n",
       "3           False        False       False        False        False   \n",
       "4           False        False       False        False        False   \n",
       "...           ...          ...         ...          ...          ...   \n",
       "278709      False        False       False        False        False   \n",
       "278710      False        False       False        False        False   \n",
       "278711      False        False       False        False        False   \n",
       "278712      False        False       False        False        False   \n",
       "278713      False        False       False        False        False   \n",
       "\n",
       "        ticker_ZWS  ticker_ZYME  ticker_ZYXI  \n",
       "0            False        False        False  \n",
       "1            False        False        False  \n",
       "2            False        False        False  \n",
       "3            False        False        False  \n",
       "4            False        False        False  \n",
       "...            ...          ...          ...  \n",
       "278709       False        False         True  \n",
       "278710       False        False         True  \n",
       "278711       False        False         True  \n",
       "278712       False        False         True  \n",
       "278713       False        False         True  \n",
       "\n",
       "[278714 rows x 4026 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('Data/full_rnn_data_2.csv')\n",
    "data.drop('Unnamed: 0', axis = 1, inplace= True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('lastTradeDate', axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_9300\\43202908.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann3_call_data.drop('call', axis = 1, inplace = True)\n",
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_9300\\43202908.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann3_put_data.drop('call', axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "ann3_data = data\n",
    "\n",
    "ann3_call_data = ann3_data[ann3_data.call == 1]\n",
    "ann3_put_data = ann3_data[ann3_data.call == 0]\n",
    "\n",
    "ann3_call_data.drop('call', axis = 1, inplace = True)\n",
    "ann3_put_data.drop('call', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Data shape after feature selection: (149092, 1000)\n",
      "WARNING:tensorflow:From c:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From c:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "7455/7455 [==============================] - 506s 67ms/step - loss: 820.9005\n",
      "Epoch 2/40\n",
      "7455/7455 [==============================] - 524s 70ms/step - loss: 575.1749\n",
      "Epoch 3/40\n",
      "7455/7455 [==============================] - 525s 70ms/step - loss: 410.0237\n",
      "Epoch 4/40\n",
      "7455/7455 [==============================] - 528s 71ms/step - loss: 277.6516\n",
      "Epoch 5/40\n",
      "7455/7455 [==============================] - 526s 71ms/step - loss: 221.6249\n",
      "Epoch 6/40\n",
      "7455/7455 [==============================] - 529s 71ms/step - loss: 197.2964\n",
      "Epoch 7/40\n",
      "7455/7455 [==============================] - 531s 71ms/step - loss: 154.7865\n",
      "Epoch 8/40\n",
      "7455/7455 [==============================] - 535s 72ms/step - loss: 146.3054\n",
      "Epoch 9/40\n",
      "7455/7455 [==============================] - 534s 72ms/step - loss: 139.6914\n",
      "Epoch 10/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 119.0134\n",
      "Epoch 11/40\n",
      "7455/7455 [==============================] - 535s 72ms/step - loss: 115.3608\n",
      "Epoch 12/40\n",
      "7455/7455 [==============================] - 540s 72ms/step - loss: 117.6105\n",
      "Epoch 13/40\n",
      "7455/7455 [==============================] - 540s 72ms/step - loss: 101.5560\n",
      "Epoch 14/40\n",
      "7455/7455 [==============================] - 538s 72ms/step - loss: 94.0969\n",
      "Epoch 15/40\n",
      "7455/7455 [==============================] - 540s 72ms/step - loss: 89.6057\n",
      "Epoch 16/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 85.6148\n",
      "Epoch 17/40\n",
      "7455/7455 [==============================] - 540s 72ms/step - loss: 89.0218\n",
      "Epoch 18/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 73.5897\n",
      "Epoch 19/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 68.9472\n",
      "Epoch 20/40\n",
      "7455/7455 [==============================] - 533s 71ms/step - loss: 71.0624\n",
      "Epoch 21/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 66.6331\n",
      "Epoch 22/40\n",
      "7455/7455 [==============================] - 537s 72ms/step - loss: 67.2127\n",
      "Epoch 23/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 63.8697\n",
      "Epoch 24/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 67.3402\n",
      "Epoch 25/40\n",
      "7455/7455 [==============================] - 538s 72ms/step - loss: 65.7271\n",
      "Epoch 26/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 58.4908\n",
      "Epoch 27/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 53.5562\n",
      "Epoch 28/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 53.8792\n",
      "Epoch 29/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 57.1479\n",
      "Epoch 30/40\n",
      "7455/7455 [==============================] - 538s 72ms/step - loss: 49.5973\n",
      "Epoch 31/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 49.9126\n",
      "Epoch 32/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 50.9808\n",
      "Epoch 33/40\n",
      "7455/7455 [==============================] - 537s 72ms/step - loss: 47.8717\n",
      "Epoch 34/40\n",
      "7455/7455 [==============================] - 534s 72ms/step - loss: 50.4738\n",
      "Epoch 35/40\n",
      "7455/7455 [==============================] - 539s 72ms/step - loss: 52.2267\n",
      "Epoch 36/40\n",
      "7455/7455 [==============================] - 537s 72ms/step - loss: 48.1015\n",
      "Epoch 37/40\n",
      "7455/7455 [==============================] - 536s 72ms/step - loss: 46.9473\n",
      "Epoch 38/40\n",
      "7455/7455 [==============================] - 540s 72ms/step - loss: 47.2529\n",
      "Epoch 39/40\n",
      "7455/7455 [==============================] - 538s 72ms/step - loss: 43.9099\n",
      "Epoch 40/40\n",
      "7455/7455 [==============================] - 537s 72ms/step - loss: 45.7277\n",
      "932/932 [==============================] - 13s 12ms/step - loss: 64.8855\n",
      "Test Loss: 64.88548278808594\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "# ann3_call_data = pd.read_csv('your_data.csv')  # Uncomment and modify this line to load your data\n",
    "\n",
    "# Separate features and target\n",
    "y = ann3_call_data['price']\n",
    "X = ann3_call_data.drop('price', axis=1)\n",
    "\n",
    "# Handle categorical data by one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "X.dropna(inplace=True)\n",
    "y = y[X.index]  # Keep the target values corresponding to the filtered features\n",
    "\n",
    "# Convert to more memory-efficient data types\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature selection (optional, adjust k based on your needs)\n",
    "k = 1000  # Number of top features to keep\n",
    "selector = SelectKBest(f_regression, k=k)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "print(f\"Data shape after feature selection: {X_selected.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Reshape the data to 3D format for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build RNN model\n",
    "RNN_model = Sequential()\n",
    "RNN_model.add(LSTM(400, input_shape=(1, X_train_reshaped.shape[2]), activation='relu', return_sequences=True))\n",
    "RNN_model.add(LSTM(400, activation='relu', return_sequences=True))\n",
    "RNN_model.add(LSTM(400, activation='relu'))\n",
    "RNN_model.add(Dense(1))\n",
    "\n",
    "# Compile the model with a lower learning rate and gradient clipping\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "RNN_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Train the RNN model\n",
    "batch_size = 512  # Adjust based on memory constraints\n",
    "RNN_model.fit(X_train_reshaped, y_train, epochs=40, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = RNN_model.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model.save('models\\\\rnn\\RNN_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after feature selection: (128952, 1000)\n",
      "Epoch 1/40\n",
      "6448/6448 [==============================] - 429s 66ms/step - loss: 513.4741\n",
      "Epoch 2/40\n",
      "6448/6448 [==============================] - 428s 66ms/step - loss: 400.8830\n",
      "Epoch 3/40\n",
      "6448/6448 [==============================] - 425s 66ms/step - loss: 302.5637\n",
      "Epoch 4/40\n",
      "6448/6448 [==============================] - 425s 66ms/step - loss: 230.2968\n",
      "Epoch 5/40\n",
      "6448/6448 [==============================] - 425s 66ms/step - loss: 169.3755\n",
      "Epoch 6/40\n",
      "6448/6448 [==============================] - 436s 68ms/step - loss: 142.6531\n",
      "Epoch 7/40\n",
      "6448/6448 [==============================] - 467s 72ms/step - loss: 132.5991\n",
      "Epoch 8/40\n",
      "6448/6448 [==============================] - 466s 72ms/step - loss: 114.2160\n",
      "Epoch 9/40\n",
      "6448/6448 [==============================] - 463s 72ms/step - loss: 102.9977\n",
      "Epoch 10/40\n",
      "6448/6448 [==============================] - 463s 72ms/step - loss: 96.9478\n",
      "Epoch 11/40\n",
      "6448/6448 [==============================] - 462s 72ms/step - loss: 93.7136\n",
      "Epoch 12/40\n",
      "6448/6448 [==============================] - 462s 72ms/step - loss: 83.2227\n",
      "Epoch 13/40\n",
      "6448/6448 [==============================] - 461s 72ms/step - loss: 82.8855\n",
      "Epoch 14/40\n",
      "6448/6448 [==============================] - 457s 71ms/step - loss: 75.7365\n",
      "Epoch 15/40\n",
      "6448/6448 [==============================] - 461s 71ms/step - loss: 67.0840\n",
      "Epoch 16/40\n",
      "6448/6448 [==============================] - 461s 71ms/step - loss: 72.4699\n",
      "Epoch 17/40\n",
      "6448/6448 [==============================] - 460s 71ms/step - loss: 65.1498\n",
      "Epoch 18/40\n",
      "6448/6448 [==============================] - 461s 71ms/step - loss: 60.4929\n",
      "Epoch 19/40\n",
      "6448/6448 [==============================] - 462s 72ms/step - loss: 58.5833\n",
      "Epoch 20/40\n",
      "6448/6448 [==============================] - 433s 67ms/step - loss: 59.4694\n",
      "Epoch 21/40\n",
      "6448/6448 [==============================] - 499s 77ms/step - loss: 55.7497\n",
      "Epoch 22/40\n",
      "6448/6448 [==============================] - 514s 80ms/step - loss: 51.7214\n",
      "Epoch 23/40\n",
      "6448/6448 [==============================] - 520s 81ms/step - loss: 52.8985\n",
      "Epoch 24/40\n",
      "6448/6448 [==============================] - 512s 79ms/step - loss: 48.4552\n",
      "Epoch 25/40\n",
      "6448/6448 [==============================] - 435s 68ms/step - loss: 47.9886\n",
      "Epoch 26/40\n",
      "6448/6448 [==============================] - 443s 69ms/step - loss: 46.2124\n",
      "Epoch 27/40\n",
      "6448/6448 [==============================] - 436s 68ms/step - loss: 43.5336\n",
      "Epoch 28/40\n",
      "6448/6448 [==============================] - 424s 66ms/step - loss: 42.6125\n",
      "Epoch 29/40\n",
      "6448/6448 [==============================] - 488s 76ms/step - loss: 41.3420\n",
      "Epoch 30/40\n",
      "6448/6448 [==============================] - 451s 70ms/step - loss: 39.6882\n",
      "Epoch 31/40\n",
      "6448/6448 [==============================] - 477s 74ms/step - loss: 42.5715\n",
      "Epoch 32/40\n",
      "   1/6448 [..............................] - ETA: 8:09 - loss: 12.7277"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Train the RNN model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m  \u001b[38;5;66;03m# Adjust based on memory constraints\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m RNN_put\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m RNN_put\u001b[38;5;241m.\u001b[39mevaluate(X_test_reshaped, y_test)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "# ann3_call_data = pd.read_csv('your_data.csv')  # Uncomment and modify this line to load your data\n",
    "\n",
    "# Separate features and target\n",
    "y = ann3_put_data['price']\n",
    "X = ann3_put_data.drop('price', axis=1)\n",
    "\n",
    "# Handle categorical data by one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "X.dropna(inplace=True)\n",
    "y = y[X.index]  # Keep the target values corresponding to the filtered features\n",
    "\n",
    "# Convert to more memory-efficient data types\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature selection (optional, adjust k based on your needs)\n",
    "k = 1000  # Number of top features to keep\n",
    "selector = SelectKBest(f_regression, k=k)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "print(f\"Data shape after feature selection: {X_selected.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Reshape the data to 3D format for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build RNN model\n",
    "RNN_put = Sequential()\n",
    "RNN_put.add(LSTM(400, input_shape=(1, X_train_reshaped.shape[2]), activation='relu', return_sequences=True))\n",
    "RNN_put.add(LSTM(400, activation='relu', return_sequences=True))\n",
    "RNN_put.add(LSTM(400, activation='relu'))\n",
    "RNN_put.add(Dense(1))\n",
    "\n",
    "# Compile the model with a lower learning rate and gradient clipping\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "RNN_put.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Train the RNN model\n",
    "batch_size = 512  # Adjust based on memory constraints\n",
    "RNN_put.fit(X_train_reshaped, y_train, epochs=40, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = RNN_put.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_put.save('models\\\\rnn\\RNN_put.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
