{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Use read_csv() to load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('Data/full_data.csv',low_memory=False)\n",
    "\n",
    "ann2_variables = [\n",
    "    'strike',\n",
    "    'stock',\n",
    "    'tau',\n",
    "    'sigma',\n",
    "    'price',\n",
    "    'call',\n",
    "    'dividendRate',\n",
    "    'dividendYield',\n",
    "    'fiveYearAvgDividendYield',\n",
    "]\n",
    "\n",
    "\n",
    "ann2_data = data[ann2_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_4272\\3590972737.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann2_call_data.drop('call', axis = 1, inplace = True)\n",
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_4272\\3590972737.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann2_put_data.drop('call', axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "ann2_call_data = ann2_data[ann2_data.call == 1]\n",
    "ann2_put_data = ann2_data[ann2_data.call == 0]\n",
    "\n",
    "ann2_call_data.drop('call', axis = 1, inplace = True)\n",
    "ann2_put_data.drop('call', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_call_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_call_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "973/973 [==============================] - 6s 3ms/step - loss: 1059.5591\n",
      "Epoch 2/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 772.6454\n",
      "Epoch 3/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 725.8804\n",
      "Epoch 4/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 696.0984\n",
      "Epoch 5/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 772.5214\n",
      "Epoch 6/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 737.4769\n",
      "Epoch 7/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 692.4070\n",
      "Epoch 8/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 699.4277\n",
      "Epoch 9/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 710.3552\n",
      "Epoch 10/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 685.3241\n",
      "Epoch 11/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 685.4766\n",
      "Epoch 12/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 704.2265\n",
      "Epoch 13/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 715.2895\n",
      "Epoch 14/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 666.9464\n",
      "Epoch 15/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 664.1373\n",
      "Epoch 16/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 648.7818\n",
      "Epoch 17/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 664.4802\n",
      "Epoch 18/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 652.2955\n",
      "Epoch 19/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 645.3031\n",
      "Epoch 20/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 714.1876\n",
      "Epoch 21/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 688.3759\n",
      "Epoch 22/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 666.5071\n",
      "Epoch 23/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 663.5961\n",
      "Epoch 24/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 668.0349\n",
      "Epoch 25/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 650.4314\n",
      "Epoch 26/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 634.9760\n",
      "Epoch 27/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 665.0353\n",
      "Epoch 28/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 674.7123\n",
      "Epoch 29/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 666.3282\n",
      "Epoch 30/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 648.3770\n",
      "Epoch 31/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 644.5865\n",
      "Epoch 32/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 665.7748\n",
      "Epoch 33/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 640.9617\n",
      "Epoch 34/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 678.8272\n",
      "Epoch 35/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 650.3488\n",
      "Epoch 36/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 668.1476\n",
      "Epoch 37/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 646.0141\n",
      "Epoch 38/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 682.6755\n",
      "Epoch 39/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 617.3857\n",
      "Epoch 40/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 656.6089\n",
      "Epoch 41/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 657.4780\n",
      "Epoch 42/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 632.4048\n",
      "Epoch 43/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 640.5106\n",
      "Epoch 44/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 637.9911\n",
      "Epoch 45/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 659.9479\n",
      "Epoch 46/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 659.5451\n",
      "Epoch 47/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 651.4421\n",
      "Epoch 48/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 642.6740\n",
      "Epoch 49/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 639.1450\n",
      "Epoch 50/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 624.1993\n",
      "Epoch 51/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 640.2407\n",
      "Epoch 52/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 653.5533\n",
      "Epoch 53/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 635.8658\n",
      "Epoch 54/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 615.5130\n",
      "Epoch 55/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 642.6933\n",
      "Epoch 56/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 650.3713\n",
      "Epoch 57/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 638.3306\n",
      "Epoch 58/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 634.8819\n",
      "Epoch 59/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 664.6479\n",
      "Epoch 60/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 634.0564\n",
      "Epoch 61/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 637.3729\n",
      "Epoch 62/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 638.3967\n",
      "Epoch 63/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 647.8655\n",
      "Epoch 64/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 634.4491\n",
      "Epoch 65/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 633.3484\n",
      "Epoch 66/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 647.9949\n",
      "Epoch 67/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 617.6963\n",
      "Epoch 68/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 634.9592\n",
      "Epoch 69/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 638.8442\n",
      "Epoch 70/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 641.4329\n",
      "Epoch 71/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 614.3442\n",
      "Epoch 72/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 625.5226\n",
      "Epoch 73/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 635.9750\n",
      "Epoch 74/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 616.4236\n",
      "Epoch 75/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 628.7137\n",
      "Epoch 76/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 636.3851\n",
      "Epoch 77/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 651.3854\n",
      "Epoch 78/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 628.5970\n",
      "Epoch 79/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 625.2074\n",
      "Epoch 80/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 646.0852\n",
      "Epoch 81/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 637.6860\n",
      "Epoch 82/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 637.4081\n",
      "Epoch 83/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 643.9779\n",
      "Epoch 84/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 623.3624\n",
      "Epoch 85/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 622.1042\n",
      "Epoch 86/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 637.4119\n",
      "Epoch 87/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 610.5643\n",
      "Epoch 88/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 631.4950\n",
      "Epoch 89/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 612.8938\n",
      "Epoch 90/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 610.0229\n",
      "Epoch 91/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 645.6811\n",
      "Epoch 92/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 614.4767\n",
      "Epoch 93/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 620.7040\n",
      "Epoch 94/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 617.2330\n",
      "Epoch 95/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 631.4616\n",
      "Epoch 96/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 634.5628\n",
      "Epoch 97/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 622.9133\n",
      "Epoch 98/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 628.4098\n",
      "Epoch 99/200\n",
      "973/973 [==============================] - 2s 3ms/step - loss: 604.5261\n",
      "Epoch 100/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 620.1312\n",
      "Epoch 101/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 639.8495\n",
      "Epoch 102/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 643.3653\n",
      "Epoch 103/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 628.5527\n",
      "Epoch 104/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 627.8766\n",
      "Epoch 105/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 616.9817\n",
      "Epoch 106/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 633.2336\n",
      "Epoch 107/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 627.9290\n",
      "Epoch 108/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 619.3895\n",
      "Epoch 109/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 630.8403\n",
      "Epoch 110/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 622.9384\n",
      "Epoch 111/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 630.7999\n",
      "Epoch 112/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 618.2500\n",
      "Epoch 113/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 622.3016\n",
      "Epoch 114/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 609.0838\n",
      "Epoch 115/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 626.6879\n",
      "Epoch 116/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 618.9401\n",
      "Epoch 117/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 630.0577\n",
      "Epoch 118/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 620.8624\n",
      "Epoch 119/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 626.5281\n",
      "Epoch 120/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 596.2823\n",
      "Epoch 121/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 627.1235\n",
      "Epoch 122/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 637.1927\n",
      "Epoch 123/200\n",
      "973/973 [==============================] - 2s 2ms/step - loss: 622.6992\n",
      "Epoch 124/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 617.3795\n",
      "Epoch 125/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 602.6601\n",
      "Epoch 126/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 619.1560\n",
      "Epoch 127/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 617.2489\n",
      "Epoch 128/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 624.3405\n",
      "Epoch 129/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 607.6291\n",
      "Epoch 130/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 613.3748\n",
      "Epoch 131/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 606.2860\n",
      "Epoch 132/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 615.3010\n",
      "Epoch 133/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 618.5891\n",
      "Epoch 134/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 609.8089\n",
      "Epoch 135/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 610.6996\n",
      "Epoch 136/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 632.6848\n",
      "Epoch 137/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 614.8090\n",
      "Epoch 138/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 612.7752\n",
      "Epoch 139/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 608.3096\n",
      "Epoch 140/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 610.4133\n",
      "Epoch 141/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 621.2419\n",
      "Epoch 142/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 607.4755\n",
      "Epoch 143/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 629.1556\n",
      "Epoch 144/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 618.9065\n",
      "Epoch 145/200\n",
      "973/973 [==============================] - 3s 4ms/step - loss: 616.4244\n",
      "Epoch 146/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 614.5881\n",
      "Epoch 147/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 613.6240\n",
      "Epoch 148/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 630.3035\n",
      "Epoch 149/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 609.4130\n",
      "Epoch 150/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 596.0886\n",
      "Epoch 151/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 622.8694\n",
      "Epoch 152/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 617.8181\n",
      "Epoch 153/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 611.5775\n",
      "Epoch 154/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 610.8103\n",
      "Epoch 155/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 612.3076\n",
      "Epoch 156/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 628.4700\n",
      "Epoch 157/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 626.2320\n",
      "Epoch 158/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 618.2886\n",
      "Epoch 159/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 610.6508\n",
      "Epoch 160/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 623.3619\n",
      "Epoch 161/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 619.2026\n",
      "Epoch 162/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 611.5620\n",
      "Epoch 163/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 601.4542\n",
      "Epoch 164/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 621.0632\n",
      "Epoch 165/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 614.6160\n",
      "Epoch 166/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 626.4536\n",
      "Epoch 167/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 600.5776\n",
      "Epoch 168/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 615.5963\n",
      "Epoch 169/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 605.7986\n",
      "Epoch 170/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 612.0413\n",
      "Epoch 171/200\n",
      "973/973 [==============================] - 4s 5ms/step - loss: 632.1831\n",
      "Epoch 172/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 625.6468\n",
      "Epoch 173/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 613.1558\n",
      "Epoch 174/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 598.1223\n",
      "Epoch 175/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 608.5094\n",
      "Epoch 176/200\n",
      "973/973 [==============================] - 3s 3ms/step - loss: 604.4551\n",
      "Epoch 177/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 601.0416\n",
      "Epoch 178/200\n",
      "973/973 [==============================] - 4s 5ms/step - loss: 607.8233\n",
      "Epoch 179/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 623.1185\n",
      "Epoch 180/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 607.8869\n",
      "Epoch 181/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 617.6194\n",
      "Epoch 182/200\n",
      "973/973 [==============================] - 4s 5ms/step - loss: 606.7406\n",
      "Epoch 183/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 614.5039\n",
      "Epoch 184/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 614.0925\n",
      "Epoch 185/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 613.6204\n",
      "Epoch 186/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 602.2368\n",
      "Epoch 187/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 599.3540\n",
      "Epoch 188/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 599.8005\n",
      "Epoch 189/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 610.8821\n",
      "Epoch 190/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 587.2241\n",
      "Epoch 191/200\n",
      "973/973 [==============================] - 6s 6ms/step - loss: 608.7913\n",
      "Epoch 192/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 596.0344\n",
      "Epoch 193/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 599.0333\n",
      "Epoch 194/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 593.4718\n",
      "Epoch 195/200\n",
      "973/973 [==============================] - 4s 5ms/step - loss: 615.6241\n",
      "Epoch 196/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 609.1036\n",
      "Epoch 197/200\n",
      "973/973 [==============================] - 5s 5ms/step - loss: 600.0811\n",
      "Epoch 198/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 595.2829\n",
      "Epoch 199/200\n",
      "973/973 [==============================] - 6s 6ms/step - loss: 611.4420\n",
      "Epoch 200/200\n",
      "973/973 [==============================] - 4s 4ms/step - loss: 601.5287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b1b3c6b990>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN2_call = Sequential()\n",
    "ANN2_call.add(Dense(30,input_dim = 7, activation = 'relu'))\n",
    "ANN2_call.add(Dense(30, activation = 'relu'))\n",
    "ANN2_call.add(Dense(30, activation = 'relu'))\n",
    "ANN2_call.add(Dense(30, activation = 'relu'))\n",
    "ANN2_call.add(Dense(1))\n",
    "\n",
    "ANN2_call.compile(loss = 'mean_squared_error',optimizer = 'Adam')\n",
    "ANN2_call.fit(X_train,y_train,epochs = 200, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_call_data[['strike', 'stock', 'tau', 'sigma', 'dividendRate','dividendYield','fiveYearAvgDividendYield',]]\n",
    "y = ann2_call_data['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ANN2_call.predict(X_test)\n",
    "\n",
    "# Plot the true values against the predictions\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('ANN 2 Call')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_put_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_put_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "857/857 [==============================] - 4s 3ms/step - loss: 457.9953\n",
      "Epoch 2/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 348.7011\n",
      "Epoch 3/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 313.1118\n",
      "Epoch 4/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 285.3506\n",
      "Epoch 5/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 302.2818\n",
      "Epoch 6/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 362.7919\n",
      "Epoch 7/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 285.0510\n",
      "Epoch 8/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 305.5459\n",
      "Epoch 9/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 275.8454\n",
      "Epoch 10/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 282.4849\n",
      "Epoch 11/200\n",
      "857/857 [==============================] - 3s 3ms/step - loss: 313.8867\n",
      "Epoch 12/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 268.1419\n",
      "Epoch 13/200\n",
      "857/857 [==============================] - 2s 3ms/step - loss: 263.4572\n",
      "Epoch 14/200\n",
      "168/857 [====>.........................] - ETA: 1s - loss: 327.9926"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m ANN2_put\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m ANN2_put\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m ANN2_put\u001b[38;5;241m.\u001b[39mfit(X_train,y_train,epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\engine\\training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1799\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m         ):\n\u001b[0;32m   1806\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\domen\\anaconda3m\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m    536\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ANN2_put = Sequential()\n",
    "ANN2_put.add(Dense(30, input_dim=7, activation='relu'))\n",
    "ANN2_put.add(Dense(30, activation='relu'))\n",
    "ANN2_put.add(Dense(30, activation='relu'))\n",
    "ANN2_put.add(Dense(30, activation='relu'))\n",
    "ANN2_put.add(Dense(30, activation='relu'))\n",
    "ANN2_put.add(Dense(30, activation='relu'))\n",
    "ANN2_put.add(Dense(1))\n",
    "\n",
    "ANN2_put.compile(loss = 'mean_squared_error',optimizer = 'Adam')\n",
    "ANN2_put.fit(X_train,y_train,epochs = 200, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ANN2_put.predict(X_test)\n",
    "\n",
    "# Plot the true values against the predictions\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('ANN 2 Put')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN2_call.save('models\\\\ann2\\ANN2_call.keras')\n",
    "ANN2_put.save('models\\\\ann2\\ANN2_put.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERFORMANCE FOR CALL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "ANN2_call = load_model('models\\\\ann2\\\\ANN2_call.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_call_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_call_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>307.5</td>\n",
       "      <td>321.06</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.420430</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36007</th>\n",
       "      <td>90.0</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.711829</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63829</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.633917</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>185.0</td>\n",
       "      <td>108.06</td>\n",
       "      <td>0.146825</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69910</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>1760.0</td>\n",
       "      <td>1000.68</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.960084</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35324</th>\n",
       "      <td>8.0</td>\n",
       "      <td>32.72</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.791322</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39515</th>\n",
       "      <td>121.0</td>\n",
       "      <td>111.91</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.513559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17752</th>\n",
       "      <td>84.0</td>\n",
       "      <td>77.02</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.254547</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>250.0</td>\n",
       "      <td>180.49</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.444977</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7779 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike    stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "10271   307.5   321.06  0.003968  0.420430          0.00         0.0000   \n",
       "36007    90.0    64.41  0.023810  0.711829          0.00         0.0000   \n",
       "63829     5.0    10.56  0.083333  0.633917          0.00         0.0000   \n",
       "24995   185.0   108.06  0.146825  0.261064          1.44         0.0123   \n",
       "69910    10.0     7.16  0.142857  0.333159          0.00         0.0000   \n",
       "...       ...      ...       ...       ...           ...            ...   \n",
       "13355  1760.0  1000.68  0.007937  0.960084          0.00         0.0000   \n",
       "35324     8.0    32.72  0.138889  0.791322          0.00         0.0000   \n",
       "39515   121.0   111.91  0.003968  0.513559          0.00         0.0000   \n",
       "17752    84.0    77.02  0.003968  0.254547          0.00         0.0000   \n",
       "36475   250.0   180.49  0.083333  0.444977          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield  \n",
       "10271                      0.00  \n",
       "36007                      0.00  \n",
       "63829                      0.00  \n",
       "24995                      0.92  \n",
       "69910                      0.00  \n",
       "...                         ...  \n",
       "13355                      0.00  \n",
       "35324                      0.00  \n",
       "39515                      0.00  \n",
       "17752                      0.00  \n",
       "36475                      0.00  \n",
       "\n",
       "[7779 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>ann2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>307.5</td>\n",
       "      <td>321.06</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.420430</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.971061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36007</th>\n",
       "      <td>90.0</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.711829</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63829</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.633917</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.114547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>185.0</td>\n",
       "      <td>108.06</td>\n",
       "      <td>0.146825</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.317830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69910</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.180138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>1760.0</td>\n",
       "      <td>1000.68</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.960084</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35324</th>\n",
       "      <td>8.0</td>\n",
       "      <td>32.72</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.791322</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.354351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39515</th>\n",
       "      <td>121.0</td>\n",
       "      <td>111.91</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.513559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.631215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17752</th>\n",
       "      <td>84.0</td>\n",
       "      <td>77.02</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.254547</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.783001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>250.0</td>\n",
       "      <td>180.49</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.444977</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.736788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7779 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike    stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "10271   307.5   321.06  0.003968  0.420430          0.00         0.0000   \n",
       "36007    90.0    64.41  0.023810  0.711829          0.00         0.0000   \n",
       "63829     5.0    10.56  0.083333  0.633917          0.00         0.0000   \n",
       "24995   185.0   108.06  0.146825  0.261064          1.44         0.0123   \n",
       "69910    10.0     7.16  0.142857  0.333159          0.00         0.0000   \n",
       "...       ...      ...       ...       ...           ...            ...   \n",
       "13355  1760.0  1000.68  0.007937  0.960084          0.00         0.0000   \n",
       "35324     8.0    32.72  0.138889  0.791322          0.00         0.0000   \n",
       "39515   121.0   111.91  0.003968  0.513559          0.00         0.0000   \n",
       "17752    84.0    77.02  0.003968  0.254547          0.00         0.0000   \n",
       "36475   250.0   180.49  0.083333  0.444977          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield       ann2  \n",
       "10271                      0.00  14.971061  \n",
       "36007                      0.00   0.132967  \n",
       "63829                      0.00   5.114547  \n",
       "24995                      0.92   0.317830  \n",
       "69910                      0.00   0.180138  \n",
       "...                         ...        ...  \n",
       "13355                      0.00   0.941292  \n",
       "35324                      0.00  21.354351  \n",
       "39515                      0.00   0.631215  \n",
       "17752                      0.00   1.783001  \n",
       "36475                      0.00   0.736788  \n",
       "\n",
       "[7779 rows x 8 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['ann2'] = ANN2_call.predict(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>ann2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>307.5</td>\n",
       "      <td>321.06</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.420430</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.971061</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36007</th>\n",
       "      <td>90.0</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.711829</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132967</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63829</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.633917</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.114547</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>185.0</td>\n",
       "      <td>108.06</td>\n",
       "      <td>0.146825</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.317830</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69910</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.180138</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>1760.0</td>\n",
       "      <td>1000.68</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.960084</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941292</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35324</th>\n",
       "      <td>8.0</td>\n",
       "      <td>32.72</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.791322</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.354351</td>\n",
       "      <td>27.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39515</th>\n",
       "      <td>121.0</td>\n",
       "      <td>111.91</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.513559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.631215</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17752</th>\n",
       "      <td>84.0</td>\n",
       "      <td>77.02</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.254547</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.783001</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>250.0</td>\n",
       "      <td>180.49</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.444977</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.736788</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7779 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike    stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "10271   307.5   321.06  0.003968  0.420430          0.00         0.0000   \n",
       "36007    90.0    64.41  0.023810  0.711829          0.00         0.0000   \n",
       "63829     5.0    10.56  0.083333  0.633917          0.00         0.0000   \n",
       "24995   185.0   108.06  0.146825  0.261064          1.44         0.0123   \n",
       "69910    10.0     7.16  0.142857  0.333159          0.00         0.0000   \n",
       "...       ...      ...       ...       ...           ...            ...   \n",
       "13355  1760.0  1000.68  0.007937  0.960084          0.00         0.0000   \n",
       "35324     8.0    32.72  0.138889  0.791322          0.00         0.0000   \n",
       "39515   121.0   111.91  0.003968  0.513559          0.00         0.0000   \n",
       "17752    84.0    77.02  0.003968  0.254547          0.00         0.0000   \n",
       "36475   250.0   180.49  0.083333  0.444977          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield       ann2  price  \n",
       "10271                      0.00  14.971061  14.50  \n",
       "36007                      0.00   0.132967   0.01  \n",
       "63829                      0.00   5.114547   5.30  \n",
       "24995                      0.92   0.317830   0.03  \n",
       "69910                      0.00   0.180138   0.10  \n",
       "...                         ...        ...    ...  \n",
       "13355                      0.00   0.941292   0.04  \n",
       "35324                      0.00  21.354351  27.30  \n",
       "39515                      0.00   0.631215   1.75  \n",
       "17752                      0.00   1.783001   0.19  \n",
       "36475                      0.00   0.736788   0.30  \n",
       "\n",
       "[7779 rows x 9 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['price'] = y_test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 729.8113731988603\n",
      "Root Mean Squared Error (RMSE): 27.015021251127312\n",
      "Mean Absolute Error (MAE): 5.493070479203191\n",
      "Mean Absolute Percentage Error (MAPE): 761.4551445709873\n",
      "R-squared: 0.888293035229748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "ANN2_call_mse = mean_squared_error(X_test['price'], X_test['ann2'])\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "ANN2_call_rmse = np.sqrt(ANN2_call_mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "ANN2_call_mae = mean_absolute_error(X_test['price'], X_test['ann2'])\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "ANN2_call_mape = np.mean(np.abs((X_test['price'] - X_test['ann2']) / X_test['price'])) * 100\n",
    "\n",
    "# Calculate R-squared\n",
    "ANN2_call_r_squared = r2_score(X_test['price'], X_test['ann2'])\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", ANN2_call_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", ANN2_call_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", ANN2_call_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", ANN2_call_mape)\n",
    "print(\"R-squared:\", ANN2_call_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERFORMANCE FOR PUT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "ANN2_put = load_model('models\\\\ann2\\\\ANN2_PUT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_put_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_put_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49372</th>\n",
       "      <td>35.0</td>\n",
       "      <td>44.32</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.410373</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>138.0</td>\n",
       "      <td>147.68</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.277048</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55721</th>\n",
       "      <td>40.0</td>\n",
       "      <td>61.72</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.447565</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29949</th>\n",
       "      <td>70.0</td>\n",
       "      <td>128.69</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.630169</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59768</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.91</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.807918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>140.0</td>\n",
       "      <td>141.38</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282565</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35822</th>\n",
       "      <td>67.5</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22724</th>\n",
       "      <td>180.0</td>\n",
       "      <td>182.55</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.206939</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48638</th>\n",
       "      <td>67.5</td>\n",
       "      <td>67.65</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.444620</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19685</th>\n",
       "      <td>78.0</td>\n",
       "      <td>97.06</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6853 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike   stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "49372    35.0   44.32  0.095238  0.410373          0.00         0.0000   \n",
       "765     138.0  147.68  0.003968  0.277048          0.00         0.0000   \n",
       "55721    40.0   61.72  0.452381  0.447565          0.00         0.0000   \n",
       "29949    70.0  128.69  0.027778  0.630169          0.00         0.0000   \n",
       "59768    20.0   15.91  0.250000  0.807918          0.00         0.0000   \n",
       "...       ...     ...       ...       ...           ...            ...   \n",
       "19362   140.0  141.38  0.087302  0.282565          0.97         0.0066   \n",
       "35822    67.5   78.00  0.079365  0.286145          1.00         0.0128   \n",
       "22724   180.0  182.55  0.071429  0.206939          6.80         0.0378   \n",
       "48638    67.5   67.65  0.079365  0.444620          0.00         0.0000   \n",
       "19685    78.0   97.06  0.027778  0.598764          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield  \n",
       "49372                      0.00  \n",
       "765                        0.00  \n",
       "55721                      0.00  \n",
       "29949                      0.00  \n",
       "59768                      0.00  \n",
       "...                         ...  \n",
       "19362                      0.00  \n",
       "35822                      6.39  \n",
       "22724                      3.35  \n",
       "48638                      0.00  \n",
       "19685                      0.00  \n",
       "\n",
       "[6853 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>ann2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49372</th>\n",
       "      <td>35.0</td>\n",
       "      <td>44.32</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.410373</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.409902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>138.0</td>\n",
       "      <td>147.68</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.277048</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.062463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55721</th>\n",
       "      <td>40.0</td>\n",
       "      <td>61.72</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.447565</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.217134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29949</th>\n",
       "      <td>70.0</td>\n",
       "      <td>128.69</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.630169</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.892292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59768</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.91</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.807918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.206931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>140.0</td>\n",
       "      <td>141.38</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282565</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.288823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35822</th>\n",
       "      <td>67.5</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>6.39</td>\n",
       "      <td>1.974548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22724</th>\n",
       "      <td>180.0</td>\n",
       "      <td>182.55</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.206939</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.191567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48638</th>\n",
       "      <td>67.5</td>\n",
       "      <td>67.65</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.444620</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.588582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19685</th>\n",
       "      <td>78.0</td>\n",
       "      <td>97.06</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.096538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6853 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike   stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "49372    35.0   44.32  0.095238  0.410373          0.00         0.0000   \n",
       "765     138.0  147.68  0.003968  0.277048          0.00         0.0000   \n",
       "55721    40.0   61.72  0.452381  0.447565          0.00         0.0000   \n",
       "29949    70.0  128.69  0.027778  0.630169          0.00         0.0000   \n",
       "59768    20.0   15.91  0.250000  0.807918          0.00         0.0000   \n",
       "...       ...     ...       ...       ...           ...            ...   \n",
       "19362   140.0  141.38  0.087302  0.282565          0.97         0.0066   \n",
       "35822    67.5   78.00  0.079365  0.286145          1.00         0.0128   \n",
       "22724   180.0  182.55  0.071429  0.206939          6.80         0.0378   \n",
       "48638    67.5   67.65  0.079365  0.444620          0.00         0.0000   \n",
       "19685    78.0   97.06  0.027778  0.598764          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield      ann2  \n",
       "49372                      0.00  2.409902  \n",
       "765                        0.00  4.062463  \n",
       "55721                      0.00  2.217134  \n",
       "29949                      0.00  2.892292  \n",
       "59768                      0.00  6.206931  \n",
       "...                         ...       ...  \n",
       "19362                      0.00  7.288823  \n",
       "35822                      6.39  1.974548  \n",
       "22724                      3.35  3.191567  \n",
       "48638                      0.00  4.588582  \n",
       "19685                      0.00  2.096538  \n",
       "\n",
       "[6853 rows x 8 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['ann2'] = ANN2_put.predict(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>ann2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49372</th>\n",
       "      <td>35.0</td>\n",
       "      <td>44.32</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.410373</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.409902</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>138.0</td>\n",
       "      <td>147.68</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.277048</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.062463</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55721</th>\n",
       "      <td>40.0</td>\n",
       "      <td>61.72</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.447565</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.217134</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29949</th>\n",
       "      <td>70.0</td>\n",
       "      <td>128.69</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.630169</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.892292</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59768</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.91</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.807918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.206931</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>140.0</td>\n",
       "      <td>141.38</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282565</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.288823</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35822</th>\n",
       "      <td>67.5</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>6.39</td>\n",
       "      <td>1.974548</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22724</th>\n",
       "      <td>180.0</td>\n",
       "      <td>182.55</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.206939</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.191567</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48638</th>\n",
       "      <td>67.5</td>\n",
       "      <td>67.65</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.444620</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.588582</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19685</th>\n",
       "      <td>78.0</td>\n",
       "      <td>97.06</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.096538</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6853 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike   stock       tau     sigma  dividendRate  dividendYield  \\\n",
       "49372    35.0   44.32  0.095238  0.410373          0.00         0.0000   \n",
       "765     138.0  147.68  0.003968  0.277048          0.00         0.0000   \n",
       "55721    40.0   61.72  0.452381  0.447565          0.00         0.0000   \n",
       "29949    70.0  128.69  0.027778  0.630169          0.00         0.0000   \n",
       "59768    20.0   15.91  0.250000  0.807918          0.00         0.0000   \n",
       "...       ...     ...       ...       ...           ...            ...   \n",
       "19362   140.0  141.38  0.087302  0.282565          0.97         0.0066   \n",
       "35822    67.5   78.00  0.079365  0.286145          1.00         0.0128   \n",
       "22724   180.0  182.55  0.071429  0.206939          6.80         0.0378   \n",
       "48638    67.5   67.65  0.079365  0.444620          0.00         0.0000   \n",
       "19685    78.0   97.06  0.027778  0.598764          0.00         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield      ann2  price  \n",
       "49372                      0.00  2.409902   0.15  \n",
       "765                        0.00  4.062463   0.02  \n",
       "55721                      0.00  2.217134   0.57  \n",
       "29949                      0.00  2.892292   0.03  \n",
       "59768                      0.00  6.206931   6.00  \n",
       "...                         ...       ...    ...  \n",
       "19362                      0.00  7.288823   1.47  \n",
       "35822                      6.39  1.974548   0.08  \n",
       "22724                      3.35  3.191567   1.75  \n",
       "48638                      0.00  4.588582   0.25  \n",
       "19685                      0.00  2.096538   0.10  \n",
       "\n",
       "[6853 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['price'] = y_test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 199.31508662399722\n",
      "Root Mean Squared Error (RMSE): 14.117899511754475\n",
      "Mean Absolute Error (MAE): 4.421255609546285\n",
      "Mean Absolute Percentage Error (MAPE): 3167.201551327749\n",
      "R-squared: 0.8548733153706003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "ANN2_put_mse = mean_squared_error(X_test['price'], X_test['ann2'])\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "ANN2_put_rmse = np.sqrt(ANN2_put_mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "ANN2_put_mae = mean_absolute_error(X_test['price'], X_test['ann2'])\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "ANN2_put_mape = np.mean(np.abs((X_test['price'] - X_test['ann2']) / X_test['price'])) * 100\n",
    "\n",
    "# Calculate R-squared\n",
    "ANN2_put_r_squared = r2_score(X_test['price'], X_test['ann2'])\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", ANN2_put_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", ANN2_put_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", ANN2_put_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", ANN2_put_mape)\n",
    "print(\"R-squared:\", ANN2_put_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
