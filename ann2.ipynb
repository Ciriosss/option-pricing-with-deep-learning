{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Use read_csv() to load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('Data/full_data.csv',low_memory=False)\n",
    "\n",
    "bs_variables = [\n",
    "    'strike',\n",
    "    'stock',\n",
    "    'tau',\n",
    "    'sigma',\n",
    "    'price',\n",
    "    'call',\n",
    "    'dividendRate',\n",
    "    'dividendYield',\n",
    "    'fiveYearAvgDividendYield',\n",
    "]\n",
    "\n",
    "\n",
    "ann2_data = data[bs_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_6456\\3590972737.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann2_call_data.drop('call', axis = 1, inplace = True)\n",
      "C:\\Users\\domen\\AppData\\Local\\Temp\\ipykernel_6456\\3590972737.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ann2_put_data.drop('call', axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "ann2_call_data = ann2_data[ann2_data.call == 1]\n",
    "ann2_put_data = ann2_data[ann2_data.call == 0]\n",
    "\n",
    "ann2_call_data.drop('call', axis = 1, inplace = True)\n",
    "ann2_put_data.drop('call', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>price</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.0</td>\n",
       "      <td>407.48</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>199.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>417.32</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>200.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230.0</td>\n",
       "      <td>417.32</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>189.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235.0</td>\n",
       "      <td>404.90</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>174.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250.0</td>\n",
       "      <td>417.32</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>170.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73147</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>1.978739</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73148</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73149</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73150</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.519841</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike   stock       tau     sigma   price  dividendRate  \\\n",
       "0       210.0  407.48  0.055556  0.223118  199.70           3.0   \n",
       "1       220.0  417.32  0.003968  0.223118  200.32           3.0   \n",
       "2       230.0  417.32  0.003968  0.223118  189.90           3.0   \n",
       "3       235.0  404.90  0.126984  0.223118  174.91           3.0   \n",
       "4       250.0  417.32  0.003968  0.223118  170.23           3.0   \n",
       "...       ...     ...       ...       ...     ...           ...   \n",
       "73147     0.5    0.38  0.079365  1.978739    0.05           0.0   \n",
       "73148     1.0    7.10  0.369048  1.064334    0.10           0.0   \n",
       "73149     2.0    7.10  0.365079  1.064334    0.05           0.0   \n",
       "73150     3.0   12.50  0.519841  1.064334    0.15           0.0   \n",
       "73151     4.0   15.00  0.686508  1.064334    0.16           0.0   \n",
       "\n",
       "       dividendYield  fiveYearAvgDividendYield  \n",
       "0             0.0071                      0.95  \n",
       "1             0.0071                      0.95  \n",
       "2             0.0071                      0.95  \n",
       "3             0.0071                      0.95  \n",
       "4             0.0071                      0.95  \n",
       "...              ...                       ...  \n",
       "73147         0.0000                      0.00  \n",
       "73148         0.0000                      0.00  \n",
       "73149         0.0000                      0.00  \n",
       "73150         0.0000                      0.00  \n",
       "73151         0.0000                      0.00  \n",
       "\n",
       "[38891 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann2_call_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stock</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>price</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>210.0</td>\n",
       "      <td>406.22</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>220.0</td>\n",
       "      <td>404.52</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>235.0</td>\n",
       "      <td>405.57</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>250.0</td>\n",
       "      <td>404.06</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>255.0</td>\n",
       "      <td>414.92</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73144</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>2.166917</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73145</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.166917</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73146</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>2.166917</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73152</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.65</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73153</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>1.064334</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34263 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strike   stock       tau     sigma  price  dividendRate  dividendYield  \\\n",
       "65      210.0  406.22  0.031746  0.223118   0.01           3.0         0.0071   \n",
       "66      220.0  404.52  0.019841  0.223118   0.02           3.0         0.0071   \n",
       "67      235.0  405.57  0.095238  0.223118   0.02           3.0         0.0071   \n",
       "68      250.0  404.06  0.091270  0.223118   0.02           3.0         0.0071   \n",
       "69      255.0  414.92  0.047619  0.223118   0.02           3.0         0.0071   \n",
       "...       ...     ...       ...       ...    ...           ...            ...   \n",
       "73144     4.0    3.48  0.642857  2.166917   2.15           0.0         0.0000   \n",
       "73145     4.5    1.06  0.083333  2.166917   3.40           0.0         0.0000   \n",
       "73146     5.5    2.36  0.436508  2.166917   3.43           0.0         0.0000   \n",
       "73152     1.0   11.65  0.464286  1.064334   0.25           0.0         0.0000   \n",
       "73153     2.0   11.70  0.472222  1.064334   1.20           0.0         0.0000   \n",
       "\n",
       "       fiveYearAvgDividendYield  \n",
       "65                         0.95  \n",
       "66                         0.95  \n",
       "67                         0.95  \n",
       "68                         0.95  \n",
       "69                         0.95  \n",
       "...                         ...  \n",
       "73144                      0.00  \n",
       "73145                      0.00  \n",
       "73146                      0.00  \n",
       "73152                      0.00  \n",
       "73153                      0.00  \n",
       "\n",
       "[34263 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann2_put_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_call_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_call_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 1266.1523\n",
      "Epoch 2/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 684.9989\n",
      "Epoch 3/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 730.6456\n",
      "Epoch 4/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 704.6823\n",
      "Epoch 5/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 735.6767\n",
      "Epoch 6/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 687.0060\n",
      "Epoch 7/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 696.8115\n",
      "Epoch 8/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 723.5564\n",
      "Epoch 9/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 677.0456\n",
      "Epoch 10/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 676.5975\n",
      "Epoch 11/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 672.4601\n",
      "Epoch 12/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 686.8510\n",
      "Epoch 13/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 673.9685\n",
      "Epoch 14/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 687.6605\n",
      "Epoch 15/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 650.7625\n",
      "Epoch 16/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 652.6641\n",
      "Epoch 17/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 684.9457\n",
      "Epoch 18/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 656.6608\n",
      "Epoch 19/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 655.8386\n",
      "Epoch 20/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 654.5170\n",
      "Epoch 21/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 662.3077\n",
      "Epoch 22/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 654.0154\n",
      "Epoch 23/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 654.1777\n",
      "Epoch 24/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 625.4798\n",
      "Epoch 25/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 664.9036\n",
      "Epoch 26/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 663.0526\n",
      "Epoch 27/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 655.2135\n",
      "Epoch 28/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 647.3604\n",
      "Epoch 29/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 624.6799\n",
      "Epoch 30/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 665.3283\n",
      "Epoch 31/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 656.0513\n",
      "Epoch 32/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 643.5002\n",
      "Epoch 33/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 651.2344\n",
      "Epoch 34/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 650.7956\n",
      "Epoch 35/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 660.0999\n",
      "Epoch 36/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 643.8534\n",
      "Epoch 37/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 652.3345\n",
      "Epoch 38/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 659.1212\n",
      "Epoch 39/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 652.2037\n",
      "Epoch 40/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 658.3474\n",
      "Epoch 41/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 668.2170\n",
      "Epoch 42/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 621.5618\n",
      "Epoch 43/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 631.9379\n",
      "Epoch 44/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 631.8661\n",
      "Epoch 45/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 648.2354\n",
      "Epoch 46/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 645.8567\n",
      "Epoch 47/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 688.2325\n",
      "Epoch 48/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 653.9625\n",
      "Epoch 49/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 662.0714\n",
      "Epoch 50/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 666.5612\n",
      "Epoch 51/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 640.6517\n",
      "Epoch 52/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 648.1179\n",
      "Epoch 53/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 632.4184\n",
      "Epoch 54/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 648.4532\n",
      "Epoch 55/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 640.1246\n",
      "Epoch 56/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 643.7504\n",
      "Epoch 57/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 637.5693\n",
      "Epoch 58/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 648.6801\n",
      "Epoch 59/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 643.2717\n",
      "Epoch 60/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 632.1588\n",
      "Epoch 61/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 636.9910\n",
      "Epoch 62/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 640.2450\n",
      "Epoch 63/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 641.8411\n",
      "Epoch 64/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 657.5488\n",
      "Epoch 65/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 643.8372\n",
      "Epoch 66/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 635.6193\n",
      "Epoch 67/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 650.2694\n",
      "Epoch 68/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 647.1951\n",
      "Epoch 69/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 653.8815\n",
      "Epoch 70/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 650.8558\n",
      "Epoch 71/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 652.2949\n",
      "Epoch 72/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 633.6342\n",
      "Epoch 73/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 628.1329\n",
      "Epoch 74/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 638.4953\n",
      "Epoch 75/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 632.3986\n",
      "Epoch 76/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 647.2620\n",
      "Epoch 77/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 629.6398\n",
      "Epoch 78/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 629.1031\n",
      "Epoch 79/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 631.0936\n",
      "Epoch 80/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 645.4562\n",
      "Epoch 81/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 631.6777\n",
      "Epoch 82/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 638.9575\n",
      "Epoch 83/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 668.0359\n",
      "Epoch 84/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 643.8650\n",
      "Epoch 85/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 624.3978\n",
      "Epoch 86/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 627.8083\n",
      "Epoch 87/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 643.0172\n",
      "Epoch 88/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 637.3782\n",
      "Epoch 89/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 634.1720\n",
      "Epoch 90/150\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 618.6461\n",
      "Epoch 91/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 629.8077\n",
      "Epoch 92/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 623.7986\n",
      "Epoch 93/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 628.8425\n",
      "Epoch 94/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 629.3636\n",
      "Epoch 95/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 643.6358\n",
      "Epoch 96/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 622.8700\n",
      "Epoch 97/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 629.1348\n",
      "Epoch 98/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 629.4360\n",
      "Epoch 99/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 630.0895\n",
      "Epoch 100/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 624.8077\n",
      "Epoch 101/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 640.3995\n",
      "Epoch 102/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 618.0219\n",
      "Epoch 103/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 636.5064\n",
      "Epoch 104/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 623.3831\n",
      "Epoch 105/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 620.5966\n",
      "Epoch 106/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 632.5794\n",
      "Epoch 107/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 636.6719\n",
      "Epoch 108/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 628.4575\n",
      "Epoch 109/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 628.2778\n",
      "Epoch 110/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 624.1277\n",
      "Epoch 111/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 618.3005\n",
      "Epoch 112/150\n",
      "1945/1945 [==============================] - 9s 4ms/step - loss: 640.5758\n",
      "Epoch 113/150\n",
      "1945/1945 [==============================] - 11s 6ms/step - loss: 618.1565\n",
      "Epoch 114/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 620.0665\n",
      "Epoch 115/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 616.2074\n",
      "Epoch 116/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 625.3583\n",
      "Epoch 117/150\n",
      "1945/1945 [==============================] - 11s 6ms/step - loss: 617.3896\n",
      "Epoch 118/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 622.9371\n",
      "Epoch 119/150\n",
      "1945/1945 [==============================] - 11s 6ms/step - loss: 627.2681\n",
      "Epoch 120/150\n",
      "1945/1945 [==============================] - 11s 6ms/step - loss: 615.4527\n",
      "Epoch 121/150\n",
      "1945/1945 [==============================] - 12s 6ms/step - loss: 627.2388\n",
      "Epoch 122/150\n",
      "1945/1945 [==============================] - 10s 5ms/step - loss: 610.8840\n",
      "Epoch 123/150\n",
      "1945/1945 [==============================] - 11s 6ms/step - loss: 634.2983\n",
      "Epoch 124/150\n",
      "1945/1945 [==============================] - 9s 5ms/step - loss: 617.8702\n",
      "Epoch 125/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 612.9521\n",
      "Epoch 126/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 624.6172\n",
      "Epoch 127/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 624.6550\n",
      "Epoch 128/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 620.0880\n",
      "Epoch 129/150\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 610.0142\n",
      "Epoch 130/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 627.9470\n",
      "Epoch 131/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 629.0472\n",
      "Epoch 132/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 620.5894\n",
      "Epoch 133/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 605.9538\n",
      "Epoch 134/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 620.4749\n",
      "Epoch 135/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 620.1790\n",
      "Epoch 136/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 621.0587\n",
      "Epoch 137/150\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 611.7407\n",
      "Epoch 138/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 619.6932\n",
      "Epoch 139/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 619.3200\n",
      "Epoch 140/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 615.3148\n",
      "Epoch 141/150\n",
      "1945/1945 [==============================] - 7s 3ms/step - loss: 618.5483\n",
      "Epoch 142/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 621.6075\n",
      "Epoch 143/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 617.3089\n",
      "Epoch 144/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 629.4402\n",
      "Epoch 145/150\n",
      "1945/1945 [==============================] - 7s 4ms/step - loss: 611.4265\n",
      "Epoch 146/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 625.6903\n",
      "Epoch 147/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 609.7883\n",
      "Epoch 148/150\n",
      "1945/1945 [==============================] - 6s 3ms/step - loss: 615.1810\n",
      "Epoch 149/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 598.3515\n",
      "Epoch 150/150\n",
      "1945/1945 [==============================] - 8s 4ms/step - loss: 610.0057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e1acef1790>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN2_call = Sequential()\n",
    "ANN2_call.add(Dense(15,input_dim = 7, activation = 'relu'))\n",
    "ANN2_call.add(Dense(15, activation = 'relu'))\n",
    "ANN2_call.add(Dense(15, activation = 'relu'))\n",
    "ANN2_call.add(Dense(15, activation = 'relu'))\n",
    "ANN2_call.add(Dense(15, activation = 'relu'))\n",
    "ANN2_call.add(Dense(15, activation = 'relu'))\n",
    "ANN2_call.add(Dense(1))\n",
    "\n",
    "ANN2_call.compile(loss = 'mean_squared_error',optimizer = 'Adam')\n",
    "ANN2_call.fit(X_train,y_train,epochs = 150, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ANN2_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = ann2_put_data[[\n",
    "        'strike',\n",
    "        'stock', \n",
    "        'tau',\n",
    "        'sigma',\n",
    "        'dividendRate',\n",
    "        'dividendYield',\n",
    "        'fiveYearAvgDividendYield',\n",
    "          ]]\n",
    "y = ann2_put_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 579.2531\n",
      "Epoch 2/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 399.5002\n",
      "Epoch 3/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 326.0551\n",
      "Epoch 4/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 305.7791\n",
      "Epoch 5/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 314.7613\n",
      "Epoch 6/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 286.5433\n",
      "Epoch 7/150\n",
      "1714/1714 [==============================] - 4s 3ms/step - loss: 302.0457\n",
      "Epoch 8/150\n",
      "1714/1714 [==============================] - 4s 3ms/step - loss: 279.5893\n",
      "Epoch 9/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 263.0671\n",
      "Epoch 10/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 266.8351\n",
      "Epoch 11/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 289.3692\n",
      "Epoch 12/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 270.9497\n",
      "Epoch 13/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 289.4793\n",
      "Epoch 14/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 277.3127\n",
      "Epoch 15/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 261.9300\n",
      "Epoch 16/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 282.4126\n",
      "Epoch 17/150\n",
      "1714/1714 [==============================] - 4s 3ms/step - loss: 259.9035\n",
      "Epoch 18/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 274.0016\n",
      "Epoch 19/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 261.1001\n",
      "Epoch 20/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 260.5483\n",
      "Epoch 21/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 279.2625\n",
      "Epoch 22/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 263.5087\n",
      "Epoch 23/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 261.9967\n",
      "Epoch 24/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 258.4560\n",
      "Epoch 25/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 267.6600\n",
      "Epoch 26/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 253.7077\n",
      "Epoch 27/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 288.0804\n",
      "Epoch 28/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 251.6994\n",
      "Epoch 29/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 266.9313\n",
      "Epoch 30/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 258.8651\n",
      "Epoch 31/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 252.1944\n",
      "Epoch 32/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 268.7497\n",
      "Epoch 33/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 237.0007\n",
      "Epoch 34/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 264.9207\n",
      "Epoch 35/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 258.6019\n",
      "Epoch 36/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 275.1552\n",
      "Epoch 37/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 240.7277\n",
      "Epoch 38/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 259.5782\n",
      "Epoch 39/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 242.5208\n",
      "Epoch 40/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 239.9388\n",
      "Epoch 41/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 254.1863\n",
      "Epoch 42/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 243.3613\n",
      "Epoch 43/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 248.2967\n",
      "Epoch 44/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 254.9480\n",
      "Epoch 45/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 248.8266\n",
      "Epoch 46/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 252.6502\n",
      "Epoch 47/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 244.0849\n",
      "Epoch 48/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 242.8325\n",
      "Epoch 49/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 241.5562\n",
      "Epoch 50/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 277.1669\n",
      "Epoch 51/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 243.3503\n",
      "Epoch 52/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 260.6912\n",
      "Epoch 53/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 249.5674\n",
      "Epoch 54/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 267.4773\n",
      "Epoch 55/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 237.3832\n",
      "Epoch 56/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 242.1986\n",
      "Epoch 57/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 244.5793\n",
      "Epoch 58/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 253.5748\n",
      "Epoch 59/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 235.4543\n",
      "Epoch 60/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 266.9785\n",
      "Epoch 61/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 250.9457\n",
      "Epoch 62/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 248.8025\n",
      "Epoch 63/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 232.8098\n",
      "Epoch 64/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 240.9855\n",
      "Epoch 65/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 237.3499\n",
      "Epoch 66/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 247.6407\n",
      "Epoch 67/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 247.1683\n",
      "Epoch 68/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 265.3668\n",
      "Epoch 69/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 246.9647\n",
      "Epoch 70/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 232.8908\n",
      "Epoch 71/150\n",
      "1714/1714 [==============================] - 11s 6ms/step - loss: 237.4191\n",
      "Epoch 72/150\n",
      "1714/1714 [==============================] - 10s 6ms/step - loss: 261.7899\n",
      "Epoch 73/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 253.8232\n",
      "Epoch 74/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 240.9557\n",
      "Epoch 75/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 246.6707\n",
      "Epoch 76/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 231.8327\n",
      "Epoch 77/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 223.6622\n",
      "Epoch 78/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 238.8078\n",
      "Epoch 79/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 225.6960\n",
      "Epoch 80/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 262.2330\n",
      "Epoch 81/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 234.3667\n",
      "Epoch 82/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 238.7523\n",
      "Epoch 83/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 241.5180\n",
      "Epoch 84/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 249.4930\n",
      "Epoch 85/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 231.3123\n",
      "Epoch 86/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 232.4462\n",
      "Epoch 87/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 239.3441\n",
      "Epoch 88/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 242.0449\n",
      "Epoch 89/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 235.0181\n",
      "Epoch 90/150\n",
      "1714/1714 [==============================] - 10s 6ms/step - loss: 243.6242\n",
      "Epoch 91/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 244.4918\n",
      "Epoch 92/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 238.7943\n",
      "Epoch 93/150\n",
      "1714/1714 [==============================] - 11s 6ms/step - loss: 232.2345\n",
      "Epoch 94/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 227.6691\n",
      "Epoch 95/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 231.0983\n",
      "Epoch 96/150\n",
      "1714/1714 [==============================] - 4s 2ms/step - loss: 255.5019\n",
      "Epoch 97/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 261.1883\n",
      "Epoch 98/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 246.2871\n",
      "Epoch 99/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 224.7193\n",
      "Epoch 100/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 260.6643\n",
      "Epoch 101/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 240.7496\n",
      "Epoch 102/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 230.6887\n",
      "Epoch 103/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 234.4206\n",
      "Epoch 104/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 221.3772\n",
      "Epoch 105/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 233.8362\n",
      "Epoch 106/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 221.4284\n",
      "Epoch 107/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 217.5554\n",
      "Epoch 108/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 251.2926\n",
      "Epoch 109/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 213.6664\n",
      "Epoch 110/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 232.1643\n",
      "Epoch 111/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 230.0682\n",
      "Epoch 112/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 224.9612\n",
      "Epoch 113/150\n",
      "1714/1714 [==============================] - 10s 6ms/step - loss: 237.9339\n",
      "Epoch 114/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 237.1262\n",
      "Epoch 115/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 232.0216\n",
      "Epoch 116/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 216.3707\n",
      "Epoch 117/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 228.2701\n",
      "Epoch 118/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 226.2702\n",
      "Epoch 119/150\n",
      "1714/1714 [==============================] - 10s 6ms/step - loss: 230.2210\n",
      "Epoch 120/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 230.7748\n",
      "Epoch 121/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 221.9224\n",
      "Epoch 122/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 217.5616\n",
      "Epoch 123/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 232.9252\n",
      "Epoch 124/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 218.3504\n",
      "Epoch 125/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 234.3356\n",
      "Epoch 126/150\n",
      "1714/1714 [==============================] - 9s 5ms/step - loss: 220.4139\n",
      "Epoch 127/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 224.9624\n",
      "Epoch 128/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 228.8868\n",
      "Epoch 129/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 220.4075\n",
      "Epoch 130/150\n",
      "1714/1714 [==============================] - 8s 4ms/step - loss: 216.5148\n",
      "Epoch 131/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 241.3863\n",
      "Epoch 132/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 205.2246\n",
      "Epoch 133/150\n",
      "1714/1714 [==============================] - 4s 3ms/step - loss: 214.9236\n",
      "Epoch 134/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 215.9026\n",
      "Epoch 135/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 223.1717\n",
      "Epoch 136/150\n",
      "1714/1714 [==============================] - 6s 3ms/step - loss: 208.8199\n",
      "Epoch 137/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 230.6183\n",
      "Epoch 138/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 262.0060\n",
      "Epoch 139/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 255.6904\n",
      "Epoch 140/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 245.8340\n",
      "Epoch 141/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 232.5391\n",
      "Epoch 142/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 213.9831\n",
      "Epoch 143/150\n",
      "1714/1714 [==============================] - 8s 4ms/step - loss: 232.6620\n",
      "Epoch 144/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 236.3530\n",
      "Epoch 145/150\n",
      "1714/1714 [==============================] - 7s 4ms/step - loss: 226.3606\n",
      "Epoch 146/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 216.0801\n",
      "Epoch 147/150\n",
      "1714/1714 [==============================] - 8s 4ms/step - loss: 213.7873\n",
      "Epoch 148/150\n",
      "1714/1714 [==============================] - 8s 5ms/step - loss: 215.1059\n",
      "Epoch 149/150\n",
      "1714/1714 [==============================] - 6s 4ms/step - loss: 214.6284\n",
      "Epoch 150/150\n",
      "1714/1714 [==============================] - 5s 3ms/step - loss: 220.1137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e1aba28f10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN2_put = Sequential()\n",
    "ANN2_put.add(Dense(15,input_dim = 7, activation = 'relu'))\n",
    "ANN2_put.add(Dense(15, activation = 'relu'))\n",
    "ANN2_put.add(Dense(15, activation = 'relu'))\n",
    "ANN2_put.add(Dense(15, activation = 'relu'))\n",
    "ANN2_put.add(Dense(15, activation = 'relu'))\n",
    "ANN2_put.add(Dense(15, activation = 'relu'))\n",
    "ANN2_put.add(Dense(1))\n",
    "\n",
    "ANN2_put.compile(loss = 'mean_squared_error',optimizer = 'Adam')\n",
    "ANN2_put.fit(X_train,y_train,epochs = 150, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN2_call.save('models\\\\ann2\\ANN2_call.keras')\n",
    "ANN2_put.save('models\\\\ann2\\ANN2_put.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
